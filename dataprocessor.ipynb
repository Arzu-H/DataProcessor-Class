{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import zscore\n",
    "from datetime import datetime\n",
    "import google.generativeai as genai\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, dataframe, target_column, api_key='your_ip_key_here'):\n",
    "        self.df = dataframe.copy()\n",
    "        self.target_column = target_column        \n",
    "        self.gen_model = self.gemini_api(api_key)\n",
    "        \n",
    "\n",
    "    def handle_missing_values(self):\n",
    "      \n",
    "        for col in self.df.columns:\n",
    "            na_ratio = self.df[col].isna().mean()\n",
    "            if na_ratio > 0.4:  \n",
    "                self.df.drop(columns=[col], inplace=True)\n",
    "            elif self.df[col].dtype == 'object':  \n",
    "                self.df[col].fillna(self.df[col].mode()[0], inplace=True)\n",
    "            else:  \n",
    "                self.df[col].fillna(self.df[col].mean(), inplace=True)\n",
    "\n",
    "    def lowercase_columns(self):\n",
    "    \n",
    "        self.df.update(self.df.select_dtypes(include='object').apply(lambda x: x.str.lower()))\n",
    "\n",
    "\n",
    "    def remove_duplicates(self):\n",
    "            \n",
    "        self.df.drop_duplicates(inplace=True)\n",
    "\n",
    "    \n",
    "    def convert_data_types(self): \n",
    "\n",
    "        def isdate(string):\n",
    "            for date_format in [\"%Y-%m-%d\", \"%d-%m-%Y\", \"%m-%d-%Y\", \"%Y/%m/%d\", \"%d/%m/%Y\", \"%m/%d/%Y\",\n",
    "                                \"%Y.%m.%d\", \"%d.%m.%Y\", \"%m.%d.%Y\", \"%d %b %Y\", \"%d %B %Y\", \"%b %d, %Y\", \"%B %d, %Y\"]:\n",
    "                try:\n",
    "                    datetime.strptime(string, date_format)\n",
    "                    return True\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            return False\n",
    "            \n",
    "        for column in self.df.columns:\n",
    "            if self.df[column].dtype == \"object\":\n",
    "                if self.df[column].str.replace(',', '', regex=False).str.isdigit().all():\n",
    "                    self.df[column] = self.df[column].str.replace(',', '', regex=False).astype(int)\n",
    "                \n",
    "                elif self.df[column].str.replace('.', '', regex=False).str.isdigit().all():                \n",
    "                    self.df[column] = self.df[column].astype(float)\n",
    "\n",
    "                elif self.df[column].apply(isdate).mean() >= 0.8:\n",
    "                    self.df[column] = pd.to_datetime(self.df[column], errors='coerce')\n",
    "\n",
    "\n",
    "    \n",
    "    def handle_outliers(self, z_threshold=3):\n",
    "        \n",
    "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
    "        z_scores = self.df[numeric_cols].apply(zscore)\n",
    "        self.df = self.df[(np.abs(z_scores) < z_threshold).all(axis=1)]\n",
    "\n",
    "    \n",
    "\n",
    "    def group_infrequent_categories(self, threshold=0.05):\n",
    "        \n",
    "        for col in self.df.select_dtypes(include='object').columns:\n",
    "            freq = self.df[col].value_counts(normalize=True)\n",
    "            infrequent = freq[freq < threshold].index\n",
    "            self.df[col] = self.df[col].replace(infrequent, 'Other')\n",
    "\n",
    "    \n",
    "    \n",
    "    def split_data(self, test_size=0.2, random_state=42):\n",
    "    \n",
    "        X = self.df.drop(columns=[self.target_column]) \n",
    "        y = self.df[self.target_column]                \n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "\n",
    "    def gemini_api(self, api_key='your_ip_key_here'):\n",
    "    \n",
    "        genai.configure(api_key = api_key)\n",
    "        self.gen_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "        return self.gen_model\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def apply_encoding(self):\n",
    "\n",
    "        object_columns = self.df.select_dtypes(include='object').columns\n",
    "        \n",
    "\n",
    "        for column in object_columns:\n",
    "\n",
    "            first_10_entries = self.df[column].head(10).tolist()        \n",
    "            \n",
    "            entries_str = \", \".join(str(entry) for entry in first_10_entries)\n",
    "\n",
    "            response = self.gen_model.generate_content(f\"Here are the first 10 entries of the column '{column}': {entries_str}. Type 'ordinal' if these categories are ordinal and type 'nominal' if they are nominal \")\n",
    "            \n",
    "            retries = 0\n",
    "\n",
    "            while response not in ['ordinal', 'nominal'] and retries < 3:\n",
    "                retries+=1\n",
    "                wait_time = 2 ** retries\n",
    "                time.sleep(wait_time)\n",
    "                response = self.gen_model.generate_content(f\"Here are the first 10 entries of the column '{column}': {entries_str}. Type 'ordinal' if these categories are ordinal and type 'nominal' if they are nominal.\")  \n",
    "            \n",
    "            if retries == 3:\n",
    "                response = 'nominal'\n",
    "\n",
    "            response = response.lower()\n",
    "        \n",
    "\n",
    "            cat_num = self.df[column].nunique() \n",
    "\n",
    "            if cat_num < 10 and response == 'ordinal':\n",
    "                le = LabelEncoder()\n",
    "                self.X_train[column] = le.fit_transform(self.X_train[column])\n",
    "                self.X_test[column] = le.transform(self.X_test[column])\n",
    "\n",
    "        \n",
    "            elif cat_num < 10 and response == 'nominal': \n",
    "\n",
    "                X_combined = pd.concat([self.X_train, self.X_test], axis=0).reset_index(drop=True)\n",
    "                X_combined = pd.get_dummies(X_combined, columns= [column], dtype=int)\n",
    "\n",
    "                self.X_train = X_combined.iloc[:len(self.X_train)].reset_index(drop=True)\n",
    "                self.X_test = X_combined.iloc[len(self.X_train):].reset_index(drop=True)               \n",
    "                                                  \n",
    "                \n",
    "              \n",
    "                \n",
    "\n",
    "            elif 10 <cat_num<50 and response == 'nominal' :\n",
    "                freq_encoding = self.X_train[column].value_counts(normalize=True)\n",
    "\n",
    "                self.X_train[column] = self.X_train[column].map(freq_encoding)\n",
    "                self.X_test[column] = self.X_test[column].map(freq_encoding)\n",
    "\n",
    "                self.X_test[column] = self.X_test[column].map(freq_encoding).fillna(0)\n",
    "\n",
    "            else:\n",
    "                te = TargetEncoder()\n",
    "                self.X_train[column] = te.fit_transform(self.X_train[column])\n",
    "                self.X_test[column] = te.transform(self.X_test[column])\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    def apply_scaling(self):\n",
    "        numerical_cols = self.X_train.select_dtypes(include=['int', 'float']).columns\n",
    "\n",
    "        for column in numerical_cols:\n",
    "            if self.X_train[column].skew() > 1 or self.X_train[column].skew() < -1:                \n",
    "                    scaler = StandardScaler()\n",
    "\n",
    "            else:\n",
    "                    scaler = MinMaxScaler()\n",
    "\n",
    "            \n",
    "            \n",
    "            self.X_train[column] = scaler.fit_transform(self.X_train[[column]])\n",
    "            self.X_test[column] = scaler.transform(self.X_test[[column]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def process(self, test_size=0.2, z_threshold=3, category_threshold=0.05):\n",
    "        \n",
    "        self.handle_missing_values()         \n",
    "        self.lowercase_columns()            \n",
    "        self.remove_duplicates()            \n",
    "        self.convert_data_types()          \n",
    "        self.handle_outliers(z_threshold)   \n",
    "        self.group_infrequent_categories(threshold=category_threshold)  \n",
    "        self.split_data(test_size=test_size) \n",
    "        self.apply_encoding()              \n",
    "        self.apply_scaling()   \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
